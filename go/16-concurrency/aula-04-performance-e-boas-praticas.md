# Aula 16 - Performance e Boas PrÃ¡ticas: ConcorrÃªncia

OlÃ¡! Agora que vocÃª entende os conceitos de concorrÃªncia, Ã© crucial aprender **quando e como** usÃ¡-los de forma eficiente. Nesta aula, vamos explorar aspectos de performance, boas prÃ¡ticas, e os erros comuns que vocÃª deve evitar.

---

## ğŸš€ Performance: Como Goroutines Funcionam

### Goroutines sÃ£o Leves, mas NÃ£o Infinitas

**Fato importante:** Goroutines sÃ£o muito mais leves que threads do sistema operacional, mas ainda tÃªm limites.

**NÃºmeros tÃ­picos:**
- **Thread do OS**: ~1-2 MB de stack por thread
- **Goroutine**: ~2-8 KB de stack inicial (cresce conforme necessÃ¡rio)
- **Capacidade**: VocÃª pode ter milhÃµes de goroutines, mas hÃ¡ limites prÃ¡ticos

**Limites prÃ¡ticos:**
```go
// âœ… OK: Milhares de goroutines
for i := 0; i < 10000; i++ {
    go processar()
}

// âš ï¸ CUIDADO: MilhÃµes podem ser demais
for i := 0; i < 1000000; i++ {
    go processar() // Pode esgotar recursos
}
```

**Quando usar muitas goroutines:**
- âœ… OperaÃ§Ãµes I/O (leitura de arquivos, requisiÃ§Ãµes HTTP)
- âœ… OperaÃ§Ãµes que bloqueiam frequentemente
- âœ… Quando vocÃª precisa de alta concorrÃªncia

**Quando limitar goroutines:**
- âš ï¸ OperaÃ§Ãµes CPU-bound (cÃ¡lculos pesados)
- âš ï¸ Quando hÃ¡ recursos limitados (conexÃµes de banco, file descriptors)
- âš ï¸ Quando precisa de controle sobre uso de recursos

---

## âš¡ Performance: Channels vs Mutexes

### Channels TÃªm Overhead

**Importante:** Channels nÃ£o sÃ£o "grÃ¡tis". Eles tÃªm overhead de sincronizaÃ§Ã£o.

**ComparaÃ§Ã£o de performance:**

```go
// Mutex (mais rÃ¡pido para sincronizaÃ§Ã£o simples)
var mu sync.Mutex
mu.Lock()
contador++
mu.Unlock()

// Channel (mais lento, mas mais seguro para comunicaÃ§Ã£o)
ch <- valor
valor := <-ch
```

**Benchmark tÃ­pico:**
- **Mutex**: ~10-50 nanosegundos por operaÃ§Ã£o
- **Channel**: ~100-500 nanosegundos por operaÃ§Ã£o

**Quando usar cada um:**

âœ… **Use Mutex quando:**
- Apenas precisa proteger acesso a dados compartilhados
- NÃ£o precisa de comunicaÃ§Ã£o complexa
- Performance Ã© crÃ­tica
- OperaÃ§Ãµes sÃ£o rÃ¡pidas

âœ… **Use Channel quando:**
- Precisa de comunicaÃ§Ã£o entre goroutines
- Precisa de sincronizaÃ§Ã£o com contexto
- Quer seguir a filosofia "share by communicating"
- OperaÃ§Ãµes sÃ£o mais complexas

**Exemplo prÃ¡tico:**
```go
// âŒ EVITE: Channel para simples incremento
ch <- 1
contador += <-ch

// âœ… PREFIRA: Mutex para simples incremento
mu.Lock()
contador++
mu.Unlock()

// âœ… BOM: Channel para comunicaÃ§Ã£o real
resultado := processar(dados)
ch <- resultado
```

---

## ğŸ¯ Boas PrÃ¡ticas: Quando Usar Cada Ferramenta

### âœ… USE Goroutines Quando:

#### 1. OperaÃ§Ãµes I/O (Leitura/Escrita)

```go
// âœ… EXCELENTE uso
func buscarURLs(urls []string) {
    for _, url := range urls {
        go func(u string) {
            resp, _ := http.Get(u)
            processar(resp)
        }(url)
    }
}
```

#### 2. Processamento Paralelo de Dados

```go
// âœ… BOM uso
func processarItens(items []Item) {
    var wg sync.WaitGroup
    for _, item := range items {
        wg.Add(1)
        go func(i Item) {
            defer wg.Done()
            processar(i)
        }(item)
    }
    wg.Wait()
}
```

#### 3. Background Tasks

```go
// âœ… BOM uso
go func() {
    for {
        time.Sleep(1 * time.Minute)
        fazerBackup()
    }
}()
```

### âŒ EVITE Goroutines Quando:

#### 1. OperaÃ§Ãµes Simples e RÃ¡pidas

```go
// âŒ DESNECESSÃRIO
go func() {
    fmt.Println("OlÃ¡")
}()

// âœ… SIMPLES
fmt.Println("OlÃ¡")
```

#### 2. Sem Controle de SincronizaÃ§Ã£o

```go
// âŒ PERIGO: Goroutine pode nÃ£o terminar
go processar()
// main termina antes da goroutine!

// âœ… CORRETO: Usar WaitGroup ou channel
var wg sync.WaitGroup
wg.Add(1)
go func() {
    defer wg.Done()
    processar()
}()
wg.Wait()
```

---

## ğŸ”’ Boas PrÃ¡ticas: Mutexes

### âœ… Sempre Use Defer para Unlock

```go
// âŒ PERIGO: Pode esquecer de fazer unlock
mu.Lock()
if condicao {
    return // Esqueceu de fazer unlock!
}
mu.Unlock()

// âœ… CORRETO: Defer garante unlock
mu.Lock()
defer mu.Unlock()
if condicao {
    return // Unlock acontece automaticamente
}
```

### âœ… Proteja Apenas o NecessÃ¡rio

```go
// âŒ RUIM: Lock muito longo
mu.Lock()
dados := buscarDados() // OperaÃ§Ã£o lenta
processar(dados)
salvar(dados)
mu.Unlock()

// âœ… BOM: Lock apenas o necessÃ¡rio
dados := buscarDados() // Fora do lock
mu.Lock()
processar(dados)
salvar(dados)
mu.Unlock()
```

### âœ… Use RWMutex para Muitas Leituras

```go
// âœ… BOM: MÃºltiplos leitores simultÃ¢neos
type Cache struct {
    mu   sync.RWMutex
    data map[string]string
}

func (c *Cache) Get(key string) string {
    c.mu.RLock()         // MÃºltiplos leitores OK
    defer c.mu.RUnlock()
    return c.data[key]
}

func (c *Cache) Set(key, value string) {
    c.mu.Lock()          // Apenas 1 escritor
    defer c.mu.Unlock()
    c.data[key] = value
}
```

---

## ğŸ“ Boas PrÃ¡ticas: Channels

### âœ… Sempre Feche Channels

```go
// âŒ PERIGO: Channel nunca fechado
func gerar() <-chan int {
    ch := make(chan int)
    go func() {
        for i := 0; i < 10; i++ {
            ch <- i
        }
        // Esqueceu de fechar!
    }()
    return ch
}

// âœ… CORRETO: Sempre fechar
func gerar() <-chan int {
    ch := make(chan int)
    go func() {
        defer close(ch) // Garante fechamento
        for i := 0; i < 10; i++ {
            ch <- i
        }
    }()
    return ch
}
```

### âœ… Verifique se Channel EstÃ¡ Fechado

```go
// âœ… BOM: Verificar se fechado
for {
    valor, ok := <-ch
    if !ok {
        fmt.Println("Channel fechado")
        break
    }
    processar(valor)
}

// âœ… MELHOR: Usar range (fecha automaticamente)
for valor := range ch {
    processar(valor)
}
```

### âœ… Use Buffered Channels Apropriadamente

```go
// âŒ EVITE: Buffer muito grande sem necessidade
ch := make(chan int, 1000000) // DesperdÃ­cio de memÃ³ria

// âœ… BOM: Buffer apropriado para o caso
ch := make(chan int, 10) // Suficiente para desacoplar

// âœ… BOM: Unbuffered quando precisa sincronizaÃ§Ã£o
ch := make(chan int) // Garante sincronizaÃ§Ã£o
```

---

## ğŸ‘· Boas PrÃ¡ticas: Worker Pools

### âœ… NÃºmero de Workers Baseado em Recursos

```go
// âŒ RUIM: NÃºmero arbitrÃ¡rio
const numWorkers = 100 // Por quÃª 100?

// âœ… BOM: Baseado em recursos
const numWorkers = runtime.NumCPU() // Um por nÃºcleo para CPU-bound
const numWorkers = 10 // Fixo para I/O-bound (conexÃµes limitadas)
```

**Regra geral:**
- **CPU-bound**: `runtime.NumCPU()` ou `runtime.NumCPU() * 2`
- **I/O-bound**: Baseado em recursos limitantes (conexÃµes, file descriptors)
- **Misto**: Experimente e meÃ§a!

### âœ… Use Buffered Channels para Worker Pools

```go
// âœ… BOM: Buffer permite enviar jobs sem bloquear
jobs := make(chan Job, numWorkers*2) // Buffer suficiente

// Workers processam
for w := 0; w < numWorkers; w++ {
    go worker(jobs, results)
}

// Enviar jobs (nÃ£o bloqueia se buffer tiver espaÃ§o)
for _, job := range jobList {
    jobs <- job
}
close(jobs)
```

---

## âš ï¸ Armadilhas Comuns e Como EvitÃ¡-las

### 1. Goroutine Leak

**Problema:** Goroutine nunca termina, consumindo recursos.

```go
// âŒ LEAK: Goroutine bloqueada para sempre
func processar() {
    ch := make(chan int)
    go func() {
        ch <- 42 // Bloqueia se ninguÃ©m receber
    }()
    // Esqueceu de receber!
}

// âœ… CORRETO: Garantir que alguÃ©m recebe
func processar() {
    ch := make(chan int)
    go func() {
        ch <- 42
    }()
    valor := <-ch // Recebe o valor
}
```

**SoluÃ§Ã£o:**
- Sempre garanta que channels sejam lidos
- Use context para cancelamento
- Use select com timeout

### 2. Race Condition

**Problema:** MÃºltiplas goroutines acessam dados sem proteÃ§Ã£o.

```go
// âŒ RACE CONDITION
var contador int

func incrementar() {
    contador++ // NÃ£o protegido!
}

// âœ… CORRETO: Proteger com Mutex
var (
    contador int
    mu       sync.Mutex
)

func incrementar() {
    mu.Lock()
    defer mu.Unlock()
    contador++
}
```

**Ferramenta:** Use `go run -race` para detectar race conditions!

### 3. Deadlock

**Problema:** Goroutines bloqueadas esperando umas pelas outras.

```go
// âŒ DEADLOCK: DependÃªncia circular
ch1 := make(chan int)
ch2 := make(chan int)

go func() {
    ch1 <- <-ch2 // Espera ch2, mas ch2 espera ch1
}()

ch2 <- <-ch1 // Espera ch1, mas ch1 espera ch2
```

**SoluÃ§Ã£o:**
- Evite dependÃªncias circulares
- Use buffered channels quando apropriado
- Use select com default para nÃ£o bloquear

### 4. Usar time.Sleep em ProduÃ§Ã£o

**Problema:** `time.Sleep` nÃ£o Ã© confiÃ¡vel para sincronizaÃ§Ã£o.

```go
// âŒ RUIM: NÃ£o confiÃ¡vel
go processar()
time.Sleep(1 * time.Second) // E se demorar mais?

// âœ… CORRETO: Usar WaitGroup ou channel
var wg sync.WaitGroup
wg.Add(1)
go func() {
    defer wg.Done()
    processar()
}()
wg.Wait() // Espera realmente terminar
```

---

## ğŸ¯ PadrÃµes Recomendados

### PadrÃ£o 1: Worker Pool para I/O

```go
func processarURLs(urls []string) {
    const numWorkers = 10
    jobs := make(chan string, len(urls))
    var wg sync.WaitGroup
    
    // Criar workers
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for url := range jobs {
                processarURL(url)
            }
        }()
    }
    
    // Enviar trabalho
    for _, url := range urls {
        jobs <- url
    }
    close(jobs)
    
    wg.Wait()
}
```

### PadrÃ£o 2: Pipeline com Channels

```go
func pipeline(dados []int) {
    // Etapa 1: Gerar
    nums := gerar(dados)
    
    // Etapa 2: Processar
    processados := processar(nums)
    
    // Etapa 3: Salvar
    salvar(processados)
}
```

### PadrÃ£o 3: Select com Timeout

```go
func comTimeout() {
    ch := make(chan string)
    
    go func() {
        time.Sleep(5 * time.Second)
        ch <- "resultado"
    }()
    
    select {
    case resultado := <-ch:
        fmt.Println(resultado)
    case <-time.After(2 * time.Second):
        fmt.Println("Timeout!")
    }
}
```

---

## ğŸ“Š Quando Usar Cada Ferramenta: Guia RÃ¡pido

| SituaÃ§Ã£o | Ferramenta | Por quÃª? |
|----------|------------|----------|
| ComunicaÃ§Ã£o entre goroutines | Channel | Filosofia do Go |
| Proteger dados compartilhados | Mutex | Simples e rÃ¡pido |
| Muitas leituras, poucas escritas | RWMutex | Permite leituras paralelas |
| Esperar mÃºltiplas goroutines | WaitGroup | Simples e eficiente |
| Multiplexar channels | Select | Essencial para coordenaÃ§Ã£o |
| Controlar concorrÃªncia | Worker Pool | Limita uso de recursos |
| Timeout/Cancelamento | Select + Context | PadrÃ£o idiomÃ¡tico |
| OperaÃ§Ãµes I/O | Goroutines | Aproveita tempo de espera |
| OperaÃ§Ãµes CPU-bound | Worker Pool limitado | Evita sobrecarga |

---

## ğŸš¨ Erros CrÃ­ticos a Evitar

### âŒ NUNCA faÃ§a:

1. **Acessar dados compartilhados sem proteÃ§Ã£o**
   ```go
   // âŒ NUNCA
   contador++ // Sem mutex!
   ```

2. **Esquecer de fechar channels**
   ```go
   // âŒ NUNCA
   go func() {
       for i := 0; i < 10; i++ {
           ch <- i
       }
       // Esqueceu close(ch)!
   }()
   ```

3. **Passar WaitGroup por valor**
   ```go
   // âŒ NUNCA
   func worker(wg sync.WaitGroup) { ... }
   
   // âœ… SEMPRE
   func worker(wg *sync.WaitGroup) { ... }
   ```

4. **Usar mutex sem defer**
   ```go
   // âŒ NUNCA
   mu.Lock()
   // cÃ³digo...
   mu.Unlock() // Pode esquecer em caso de return/panic
   
   // âœ… SEMPRE
   mu.Lock()
   defer mu.Unlock()
   ```

5. **Criar goroutines sem controle**
   ```go
   // âŒ NUNCA
   for i := 0; i < 1000000; i++ {
       go processar() // Pode esgotar recursos
   }
   ```

---

## âœ… Checklist de Boas PrÃ¡ticas

Antes de finalizar seu cÃ³digo concorrente, verifique:

- [ ] Todas as goroutines tÃªm uma forma de terminar?
- [ ] Channels sÃ£o fechados quando nÃ£o hÃ¡ mais dados?
- [ ] Dados compartilhados estÃ£o protegidos com Mutex?
- [ ] WaitGroups sÃ£o passados por referÃªncia?
- [ ] Mutexes usam `defer Unlock()`?
- [ ] Worker pools tÃªm nÃºmero apropriado de workers?
- [ ] HÃ¡ tratamento de erros nas goroutines?
- [ ] NÃ£o hÃ¡ race conditions (teste com `-race`)?
- [ ] NÃ£o hÃ¡ deadlocks potenciais?
- [ ] Timeouts estÃ£o implementados onde necessÃ¡rio?

---

## ğŸ“ Resumo Final

**PrincÃ­pios fundamentais:**

1. **"Don't communicate by sharing memory; share memory by communicating"**
   - Prefira channels sobre mutexes quando possÃ­vel
   - Use mutexes apenas quando necessÃ¡rio

2. **Goroutines sÃ£o leves, mas nÃ£o infinitas**
   - Use worker pools para controlar concorrÃªncia
   - Limite baseado em recursos disponÃ­veis

3. **Sempre proteja dados compartilhados**
   - Use mutexes ou channels
   - Teste com `-race` flag

4. **Sempre limpe recursos**
   - Feche channels
   - Use WaitGroups para esperar goroutines
   - Use defer para garantir limpeza

5. **MeÃ§a e otimize**
   - NÃ£o otimize prematuramente
   - Use benchmarks para medir performance
   - Perfil seu cÃ³digo para encontrar gargalos

**Lembre-se:** ConcorrÃªncia Ã© poderosa, mas requer cuidado. Pratique, teste com `-race`, e aprenda com os erros!

Boa sorte com seus programas concorrentes! ğŸš€




